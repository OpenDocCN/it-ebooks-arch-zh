# 扩展篇

### SEO

似乎因为受这篇文章的影响 [`katemats.com/what-every-programmer-should-know-about-seo/`](http://katemats.com/what-every-programmer-should-know-about-seo/) 于是我也觉得我应该写一个[每个程序员必知之 SEO](http://www.phodal.com/blog/every-programmer-should-know-how-seo/)，作为一个擅长前端兼 SEO 的设计师。

#### 搜索引擎是如何工作的

> 如果你有时间，可以读一下谷歌的框架：

[`infolab.stanford.edu/~backrub/google.html`](http://infolab.stanford.edu/~backrub/google.html)

> 这是一个老的，有些过时纸，但非常平易近人，甚至在我们中间的非白皮书的读者图标微笑什么每个程序员都应该知道的关于搜索引擎优化和他们绝对概念的解释更详细，我只提一笔带过。

搜索时发生什么了 ？

*   用户输入查询内容
*   查询处理以及分词技术
*   确定搜索意图及返回相关、新鲜的内容

![search-engine-arch](img/2015-12-28_5680cac69333d.jpg)

search-engine-arch

为什么需要 SEO ？

这是一个有趣的问题，答案总会来源于`为网站带来更多的流量`。

### 爬虫与索引

我们先看看来自谷歌的爬虫工作的一点内容

> 抓取是 Googlebot 发现新网页并更新这些网页以将网页添加到 Google 索引中的过程。
> 
> 我们使用许多计算机来获取（或“抓取”）网站上的大量网页。执行获取任务的程序叫做 Googlebot（也被称为漫游器或信息采集软件）。Googlebot 使用算法来进行抓取：计算机程序会确定要抓取的网站、抓取频率以及从每个网站中获取的网页数量。
> 
> Google 的抓取过程是根据网页网址的列表进行的，该列表是在之前进行的抓取过程中形成的，且随着网站管理员所提供的站点地图数据不断进行扩充。Googlebot 在访问每个网站时，会检测每个网页上的链接，并将这些链接添加到它要抓取的网页列表中。新建立的网站、对现有网站所进行的更改以及无效链接都会被记录下 来，并用于更新 Google 索引。

也就是如原文所说:

> 谷歌的爬虫(又或者说蛛蛛)能够抓取你整个网站索引的所有页。

**为什么谷歌上可以搜索整个互联网的内容**？因为，他解析并存储了。而更有意思的是，他会为同样的内容建立一个索引或者说分类，按照一定的相关性，针对于某个关键词的内容。

PageRank 对于一个网站来说是相当重要的，只是这个相比也比较复杂。包括其他网站链接向你的网站，以及流量，当然还有域名等等。

### 什么样的网站需要 SEO？

下图是我的博客的流量来源

What Site Need SEO

正常情况下除了像`腾讯`这类的`QQ 空间`自我封闭的网站外都需要 SEO，或者不希望泄露一些用户隐私如`Facebook`、`人人`等等

*   如果你和我的网站一样需要靠搜索带来流量
*   如果你只有很少的用户访问，却有很多的内容。
*   如果你是为一个公司、企业工作为以带来业务。
*   。。。

SEO 与编程的不同之处 ？

SEO 与编程的最大不同之处在于

编程的核心是技术，SEO 的核心是内容。？

内容才是 SEO 最重要的组成部分，这也就是腾讯复制不了的东西。

### SEO 基础知识

#### 确保网站是可以被索引的

一些常见的页面不能被访问的原因

*   隐藏在需要提交的表格中的链接
*   不能解析的 JavaScript 脚本中的链接
*   Flash、Java 和其他插件中的链接
*   PowerPoint 和 PDF 文件中的链接
*   指向被 meta Robtots 标签、rel=“NoFollow”和 robots.txt 屏蔽的页面的链接
*   页面上有上几百个链接
*   frame(框架结构)和 iframe 里的链接

对于现在的网站来还有下面的原因，通过来说是因为内容是动态生成的，而不是静态的

*   网站通过 WebSocket 的方法渲染内容
*   使用诸如 Mustache 之类的 JS 模板引擎

#### 什么样的网页可以被索引

*   确保页面可以在没有 JavaScript 下能被渲染。对于现在 JavaScript 语言的使用越来越多的情况下，在使用 JS 模板引擎的时候也应该注意这样的问题。
*   在用户禁用了 JavaScript 的情况下，保证所有的链接和页面是可以访问的。
*   确保爬虫可以看到所有的内容。那些用 JS 动态加载出来的对于爬虫来说是不友好的
*   使用描述性的锚文本的网页
*   限制的页面上的链接数量。除去一些分类网站、导航网站之类有固定流量，要不容易被认为垃圾网站。
*   确保页面能被索引。有一指向它的 URL
*   URL 应该遵循最佳实践。如 blog/how-to-driver 有更好的可读性

#### 在正确的地方使用正确的关键词

*   把关键词放 URL 中
*   关键词应该是页面的标签
*   带有 H1 标签
*   图片文件名、ALT 属性带有关键词。
*   页面文字
*   加粗文字
*   Descripiton 标签

### 内容

对于技术博客而言，内容才是最需要考虑的因素。

可以考虑一下这篇文章，虽然其主题是以 SEO 为主 [用户体验与网站内容](http://www.phodal.com/blog/user-experience-writing-web-content/)

不可忽略的一些因素是内容才是最优质的部分，没有内容一切 SEO 都是无意义的。

复制内容问题 ？

一个以用户角度考虑的问题

用户需要看到多元化的搜索结果 ？

所以对于搜索引擎来说，复制带来的结果：

*   搜索引擎爬虫对每个网站都有设定的爬行预算，每一次爬行都只能爬行 trpgr 页面数
*   连向复制内容页面的链接也浪费了它们的链接权重。
*   没有一个搜索引擎详细解释他们的算法怎样选择显示页面的哪个版本。

于是上文说到的作者给了下面的这些建议:

> 避免从网上复制的内容（除非你有很多其他的内容汇总，以使它看起来不同 - 我们做头条，对我们的产品页面的新闻片段的方式） 。这当然强烈适用于在自己的网站页面以及。内容重复可以混淆搜索引擎哪些页面是权威（它也可能会导致罚款，如果你只是复制粘贴别人的内容也行） ，然后你可以有你自己的网页互相竞争排名！
> 
> 如果你必须有重复的内容，利用相对=规范，让搜索引擎知道哪个 URL 是一个他们应该被视为权威。但是，如果你的页面是另一个在网络上找到一个副本？那么开始想出一些策略来增加更多的文字和信息来区分你的网页，因为这样重复的内容是决不可能得到好的排名。

——待续。

#### 保持更新

谷歌对于一个一直在更新的博客来说会有一个好的排名，当然只是相对的。

对于一个技术博客作者来说，一直更新的好处不仅可以让我们不断地学习更多的内容。也可以保持一个良好的习惯，而对于企业来说更是如此。如果我们每天去更新我们的博客，那么搜索引擎对于我们网站的收录也会变得越来越加频繁。那么，对于我们的排名及点击量来说也算是一个好事，当我们可以获得足够的排名靠前时，我们的 PR 值也在不断地提高。

更多内容可以参考:[Google Fresh Factor](http://www.seomoz.org/blog/google-fresh-factor)

#### 网站速度

> 谷歌曾表示在他们的算法页面加载速度问题，所以一定要确保你已经调整您的网站，都服从最佳做法，以使事情迅速

过去的一个月里，我试着提高自己的网站的速度，有一个相对好的速度，但是受限于`域名解析速度`以及`VPS`。

[网站速度分析与 traceroute](http://www.phodal.com/blog/use-traceroute-analyse-person-homepage-speed/)

[UX 与网站速度优化——博客速度优化小记](http://www.phodal.com/blog/ux-and-improve-website-load-speed/)

[Nginx ngx_pagespeed nginx 前端优化模块编译](http://www.phodal.com/blog/nginx-with-ngx-pagespeed-module-improve-website-cache/)

#### 保持耐心

> 这是有道理的，如果你在需要的谷歌机器人抓取更新的页面，然后处理每一个页面，并更新与新内容对应的索引的时间因素。
> 
> 而这可能是相当长一段时间，当你正在处理的内容 PB 级。

SEO 是一个长期的过程，很少有网站可以在短期内有一个很好的位置，除非是一个热门的网站，然而在它被发现之前也会一个过程。

#### 链接

在某种意义上，这个是提高 PR 值，及网站流量的另外一个核心，除了内容以外的核心。

*   链接建设是 SEO 的基础部分。除非你有一个异常强大的品牌，不需要干什么就能吸引到链接。
*   链接建设永不停止。这是不间断营销网站的过程

关于链接的内容有太多，而且当前没有一个好的方法获取链接虽然在我的网站已经有了

Links to Your Site

Total links

`5,880`

> 同时寻求更多的链接是更有利更相关的链接可以帮助一样多。如果你有你的内容的分销合作伙伴，或者你建立一个小工具，或其他任何人都会把链接回你的网站在网络上 - 你可以通过确保各个环节都有最佳的关键字锚文本大大提高链路的相关性。您还应该确保所有链接到您的网站指向你的主域（ [`www.yourdomain.com`](http://www.yourdomain.com) ，像 http://widget.yourdomain.com 不是一个子域） 。另外，你要尽可能多的联系，以包含适当的替代文字。你的想法。
> 
> 另外，也许不太明显的方式，建立链接（或者至少流量）是使用社交媒体 - 所以设置你的 Facebook ，Twitter 和谷歌，每当你有新的链接一定要分享。这些通道也可以作为一个有效的渠道，推动更多的流量到您的网站。

由社交渠道带来的流量在现在已经越来越重要了，对于一些以内容为主导的网站，而且处于发展初期，可以迅速带来流量，可以参考一下这篇文章

[寻 ta 分析与网站内容](http://www.phodal.com/blog/xunta-analytics-and-website-content/)

一些更简单的办法就是交换链接，总之这个话题有些沉重，可能会带来一些负面的影响，如黑帽 SEO。。。。

**参考来源**:

《SEO 艺术》(The Art of SEO)

### 技术的本质

当我开始在阅读《技术的本质》的时候，我就开始在思考这样一个问题，我们在使用技术还是工具。

![技术的本质](img/2015-12-28_5680cac69333d.jpg)

技术的本质

### 技术与工具

在某百科上说

> 一项技术是关于某一领域有效的科学（理论和研究方法）的全部，以及在该领域为实现公共或个体目标而解决设计问题的规则的全部。

对于技术不同的人的理解可能是不同的，和上图中的使用工具类似的是，和工具一样，技术也在不断地成长和进行。网站的成长史似乎可以简化为下面的过程，可能还会有 ASP.NE 等等，只是因为我接触得比较少。

*   静态的 HTML
*   CGI 和 Perl 脚本
*   PHP
*   J2EE
*   Django
*   Ruby on Rails
*   Nodejs

实际上这是技术的一种演变，然而做为最核心的东西 HTML 似乎还是那样的。作为新技术产生的核心——HTML 也在不断也进化中。然而，没有想象中的那么明显，看上去像是不变的，只是技术在不断地向前前进。对于我们来说这些都是工具，有时我们在用工具创造中新的工具，好比是技术本身，通过结合一些技术创建出新的技术。同进化史一般，我们没有办法从无到有创造出一个新的东西，没有上帝。

而作为一个普通的程序员，我们所做的只是在使用工具，从芯片到语言，从语言到框架，从框架到实现。

### 编程的秘密

每个人在技术的成长过程中都有不同的经历，对于我来说现在的总结大概是如此(ps:有兴趣可以参考[过去的那些语言](http://www.phodal.com/blog/past-computer-language/))。

*   当我开始学习第一种语言`LOGO`时，我还小觉得很神奇，至少对于计算机还是保持神秘的。
*   当我开始学习**C++**时，由于作者对于其优雅的宣称，我觉得**C++**确实很优雅、
*   当我开始学习`Python`的时候，我发现**简单**才是我所要追求的。
*   当我开始学习**Ruby On Rails**的时候，我发现生成可以很强大，但是因为强大，所以没有意思。
*   当我开始学习`Django`的时候，我发现这才是我想要的订制。
*   当我开始写`博客`的时候，我觉得比于**HTML**来说，**Markdown**才是适合我的。
*   当我开始写下此文时，我开始觉得我**应该试着去做点什么**。

于是我又回到了原点，开始迷茫我想要的是什么？当我实习半年以后，我学到了更多的东西（[实习半年后:正在变得高效](http://www.phodal.com/blog/thoughtworks-intern-how-to-be-a-zen-programmer/)），而我开始的时候我才在偶然的一次机会中才了解到，我们用的都是工具。只是，我们可以用工具创造出工具。

编程只是用来解决问题的工具，优美与否对于解决问题的帮助，取决于是一次性问题还是长期问题。编程的核心是解决问题，正如 SEO 的核心是内容(详情见:[每个程序员必知之 SEO](http://www.phodal.com/blog/every-programmer-should-know-how-seo/))。于是，

> 我们把一个又一个的迷团解开了，剩下百无聊赖。

当我们在讨论生产率的时候，得知高级语言会比低级语言来得有生产率，但是效率可能会因人而异。高级语言来自于低级语言，这些似乎没有那么重要。人们熟悉了不同的 IDE、不同的语言，相比于那些入门者来说，谙熟语言的人只是更加熟练罢了。同《卖油翁》的`我亦无他，唯手熟尔`般，对于有些东西只是因为用多了，然后熟悉罢了。事实真的是这样么？如果我们每天写的是**1+1=2**，我们会知道**1+2=3**么。

> 那么所谓的优秀的程序员和普通的程序员的差别在哪?

### 技术的成长

这里的技术指的不是个人在技术上的成长，而是技术自身的成长。

> 技术在某种程度上一定是来自此前已有技术的新的组合。

一个优秀的框架、软件、系统的产生必然会基于其他的已有技术或者框架，如：

Ubuntu GNU/Linux

*   内核是 Linux
*   编译器 GCC
*   库 GLIBC 等等
*   脚本语言 Python 等
*   Bash
*   等

而这其中的一些小命令如 ls、cd、wget 也是这个系统的组成部分之一，我们无法找到一个不依赖于其他系统的软件。如果你自己动手编译过 Linux，或者你会更有体会一个 GNU/Linux 系统需要什么。从一个库来说它是基于其他的基本库，如 C 标准库，而从 C 标准库的编译又依赖于编译器，这些都循环中前进着。

```
       gcc4.7 编译出了 gcc4.8
 gcc4.6 编译出了 gcc4.7
 gcc4.5 编译出了 gcc4.6
 等等

```

这是对一个可以自身编译自身的编译器而言，我们无法忽视的是技术背后有许多细节。巨人是站在巨人的肩膀上，过去我们可能一群工程师一个月开发出来的软件，在今天可能可以由一个工程师一天开发出来。因为我们可以基于前人的经验及教训，而这也是所谓的高生产率的程序员和一般的程序员间的区别。

自然而然的优秀的程序员吸收了其他人的经验以及教训，换在今天来说，你今天所在的位置并不是因为你比别人聪明，或者是别人比你聪明，只是因为你**吸收了更多的知识及经验**。当然，教育不公平不应该这边的讨论范围。